{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ab37a141-0b53-4811-b922-dec42979f97c",
      "metadata": {
        "id": "ab37a141-0b53-4811-b922-dec42979f97c"
      },
      "source": [
        "# Privacy Policy TL;DR\n",
        "\n",
        "This notebook uses a transformer-based encoder-decoder model to generate a short\n",
        "TL;DR (Too Long; Didn't Read) summary of a privacy policy, highlighting key\n",
        "data collection and data sharing practices."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40987fcb-0d1a-4232-a919-36ebaf90060f",
      "metadata": {
        "id": "40987fcb-0d1a-4232-a919-36ebaf90060f"
      },
      "source": [
        "### Step 1: Import Required Library\n",
        "\n",
        "Hugging Face's AutoTokenizer and AutoModelForSeq2SeqLM are used directly to avoid\n",
        "pipeline compatibility issues and ipywidget is imported to simulate an interactive frontend within the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fd388be1-f966-45f3-afdb-32e8cf0f5fa1",
      "metadata": {
        "id": "fd388be1-f966-45f3-afdb-32e8cf0f5fa1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "import tempfile, os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f2dcd2-c3e0-47cb-bf5a-0d27ad77bd9d",
      "metadata": {
        "id": "97f2dcd2-c3e0-47cb-bf5a-0d27ad77bd9d"
      },
      "source": [
        "### Step 2: Load the Pretrained Summarization Model\n",
        "\n",
        "BART encoderâ€“decoder model is used which is well suited for abstractive\n",
        "summarization of long documents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d113df4b-b153-4a10-807f-41abd4e13ca9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d113df4b-b153-4a10-807f-41abd4e13ca9",
        "outputId": "cc522205-9b52-49be-e3d6-c7d1e1b91090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "MODEL_NAME = \"facebook/bart-large-cnn\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba7713c-d19e-4f9c-8664-4e7f9f47f692",
      "metadata": {
        "id": "aba7713c-d19e-4f9c-8664-4e7f9f47f692"
      },
      "source": [
        "### Step 3: Generate TL;DR Summary\n",
        "\n",
        "The model generates a concise summary highlighting key data collection and\n",
        "sharing practices. (Backend Function)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9101ee80-4b1d-4d79-a949-743f3c5840f0",
      "metadata": {
        "id": "9101ee80-4b1d-4d79-a949-743f3c5840f0"
      },
      "outputs": [],
      "source": [
        "def extract_data_collection_sections(text):\n",
        "    keywords = [\n",
        "    # Core data collection sections\n",
        "    \"information we collect\",\n",
        "    \"data we collect\",\n",
        "    \"your activity\",\n",
        "    \"information you provide\",\n",
        "    \"device information\",\n",
        "    \"information from partners\",\n",
        "    \"third parties\",\n",
        "    \"log data\",\n",
        "    \"usage data\",\n",
        "\n",
        "    # Personal identifiers\n",
        "    \"email\", \"e-mail\",\n",
        "    \"phone\", \"mobile\", \"contact number\",\n",
        "    \"name\", \"full name\", \"username\",\n",
        "    \"password\",\n",
        "\n",
        "    # Financial & transactional\n",
        "    \"credit card\", \"debit card\",\n",
        "    \"payment\", \"billing\",\n",
        "    \"transaction\", \"purchase\",\n",
        "    \"bank account\", \"financial information\",\n",
        "\n",
        "    # Location & network tracking\n",
        "    \"location\", \"precise location\",\n",
        "    \"gps\", \"geolocation\",\n",
        "    \"ip address\", \"ip\",\n",
        "    \"wifi\", \"bluetooth\", \"cell tower\",\n",
        "\n",
        "    # Device & cross-device tracking\n",
        "    \"device\", \"device id\",\n",
        "    \"advertising id\", \"persistent identifier\",\n",
        "    \"unique identifier\",\n",
        "    \"fingerprinting\", \"browser fingerprint\",\n",
        "\n",
        "    # Cookies & tracking tech\n",
        "    \"cookies\",\n",
        "    \"tracking\",\n",
        "    \"tracking pixel\",\n",
        "    \"sdk\",\n",
        "    \"analytics\",\n",
        "\n",
        "    # Biometric & media\n",
        "    \"biometric\",\n",
        "    \"face\", \"facial recognition\",\n",
        "    \"voice\", \"audio\",\n",
        "    \"camera\",\n",
        "    \"photos\", \"videos\",\n",
        "\n",
        "    # Communications & social graph\n",
        "    \"messages\", \"chat\",\n",
        "    \"communications\",\n",
        "    \"contacts\", \"address book\",\n",
        "    \"call logs\",\n",
        "\n",
        "    # Behaviour & profiling\n",
        "    \"browsing history\",\n",
        "    \"search history\",\n",
        "    \"interaction data\",\n",
        "    \"usage patterns\",\n",
        "    \"profiling\",\n",
        "    \"inferred\",\n",
        "    \"preferences\",\n",
        "\n",
        "    # Advertising & monetization\n",
        "    \"advertising\",\n",
        "    \"personalized advertising\",\n",
        "    \"ad targeting\",\n",
        "    \"marketing\",\n",
        "    \"promotions\",\n",
        "\n",
        "    # Data sharing & selling\n",
        "    \"data sharing\",\n",
        "    \"data transfer\",\n",
        "    \"sell\",\n",
        "    \"sale of data\",\n",
        "    \"share\",\n",
        "    \"disclose\",\n",
        "    \"vendors\",\n",
        "    \"partners\",\n",
        "    \"advertisers\",\n",
        "\n",
        "    # Legal / government sharing\n",
        "    \"law enforcement\",\n",
        "    \"government authorities\",\n",
        "    \"legal requests\",\n",
        "    \"court order\",\n",
        "\n",
        "    # Children & sensitive groups\n",
        "    \"children\",\n",
        "    \"minors\",\n",
        "    \"under the age\",\n",
        "\n",
        "    # Account & identity\n",
        "    \"account information\",\n",
        "    \"profile information\",\n",
        "    \"authentication\"\n",
        "]\n",
        "\n",
        "\n",
        "    extracted_paragraphs = []\n",
        "\n",
        "    paragraphs = text.split(\"\\n\")\n",
        "\n",
        "    for para in paragraphs:\n",
        "        para_lower = para.lower()\n",
        "        if any(k in para_lower for k in keywords):\n",
        "            extracted_paragraphs.append(para.strip())\n",
        "\n",
        "    return \"\\n\".join(extracted_paragraphs)\n",
        "\n",
        "def generate_summary(text):\n",
        "    filtered_text = extract_data_collection_sections(text)\n",
        "\n",
        "    if not filtered_text.strip():\n",
        "        filtered_text = text\n",
        "\n",
        "    prompt = (\n",
        "        \"Summarize the types of personal data that are collected, tracked, \"\n",
        "        \"stored, or shared with third parties in the following privacy policy.\\n\\n\"\n",
        "        + filtered_text\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=1024,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=320,\n",
        "        min_length=260,\n",
        "        num_beams=4,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "\n",
        "def classify_privacy_risk(summary):\n",
        "    summary = summary.lower()\n",
        "\n",
        "    high_risk_keywords = [\n",
        "        \"credit card\", \"debit card\", \"bank account\",\n",
        "        \"payment\", \"billing\", \"transaction\",\n",
        "        \"biometric\", \"facial recognition\", \"voice\",\n",
        "        \"fingerprint\",\n",
        "        \"precise location\", \"gps\", \"geolocation\",\n",
        "        \"advertising id\", \"device id\",\n",
        "        \"sell\", \"sale of data\"\n",
        "    ]\n",
        "    medium_risk_keywords = [\n",
        "        \"email\", \"phone\", \"contact number\",\n",
        "        \"username\", \"profile information\",\n",
        "        \"messages\", \"chats\", \"communications\",\n",
        "        \"photos\", \"videos\",\n",
        "        \"browsing history\", \"search history\",\n",
        "        \"ip address\", \"cookies\",\n",
        "        \"third party\", \"partners\", \"vendors\",\n",
        "        \"advertising\", \"ad targeting\"\n",
        "    ]\n",
        "\n",
        "    low_risk_keywords = [\n",
        "        \"analytics\", \"usage data\",\n",
        "        \"log data\", \"interaction data\"\n",
        "    ]\n",
        "\n",
        "    score = 0\n",
        "\n",
        "    score += 3 * sum(k in summary for k in high_risk_keywords)\n",
        "    score += 2 * sum(k in summary for k in medium_risk_keywords)\n",
        "    score += 1 * sum(k in summary for k in low_risk_keywords)\n",
        "\n",
        "    if score >= 10:\n",
        "        return \"High Privacy Risk\"\n",
        "    elif score >= 4:\n",
        "        return \"Moderate Privacy Risk\"\n",
        "    else:\n",
        "        return \"Low Privacy Risk\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bbefad9-2ddf-4cc4-a0c5-d50a5237a70f",
      "metadata": {
        "id": "6bbefad9-2ddf-4cc4-a0c5-d50a5237a70f"
      },
      "source": [
        "### Step 4: Build an Interactive Frontend\n",
        "\n",
        "In this step, an interactive user interface is created using ipywidgets. A text area allows the user to paste a privacy policy, while a button enables the user to trigger the analysis and get the required summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448506f7-4b47-46e9-a2de-25d0a7f0e212",
      "metadata": {
        "id": "448506f7-4b47-46e9-a2de-25d0a7f0e212"
      },
      "outputs": [],
      "source": [
        "policy_input = widgets.Textarea(\n",
        "    placeholder=\"Paste privacy policy text here or upload a .txt document below using 'Upload' (TEXT ONLY)...\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"220px\")\n",
        ")\n",
        "\n",
        "file_upload = widgets.FileUpload(\n",
        "    accept=\".txt\",\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "upload_status = widgets.Label(\"No file uploaded.\")\n",
        "\n",
        "analyze_button = widgets.Button(\n",
        "    description=\"Generate Summary\",\n",
        "    button_style=\"success\"\n",
        ")\n",
        "\n",
        "clear_button = widgets.Button(\n",
        "    description=\"Clear Input\",\n",
        "    button_style=\"warning\"\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c690ebad-5711-4956-9afa-9266f07fe7a0",
      "metadata": {
        "id": "c690ebad-5711-4956-9afa-9266f07fe7a0"
      },
      "source": [
        "### Step 5: Analysis\n",
        "\n",
        "In this step, a simple analysis is done based on the summary for stating the privacy risk.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3789c575-db66-491f-aa48-b80ace20707c",
      "metadata": {
        "id": "3789c575-db66-491f-aa48-b80ace20707c"
      },
      "outputs": [],
      "source": [
        "def update_upload_status(change):\n",
        "    if file_upload.value:\n",
        "        upload_status.value = \"Text file uploaded.\"\n",
        "    else:\n",
        "        upload_status.value = \"No file uploaded.\"\n",
        "\n",
        "file_upload.observe(update_upload_status, names=\"value\")\n",
        "\n",
        "def on_analyze_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "\n",
        "        text = policy_input.value.strip()\n",
        "\n",
        "        if file_upload.value:\n",
        "            uploaded = next(iter(file_upload.value.values()))\n",
        "            text = uploaded[\"content\"].decode(\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "        if not text:\n",
        "            print(\"Please paste text or upload a .txt file.\")\n",
        "            return\n",
        "\n",
        "        print(\"Generating summary...\\n\")\n",
        "\n",
        "        summary = generate_summary(text)\n",
        "        risk = classify_privacy_risk(summary)\n",
        "\n",
        "        print(\"Summary:\\n\")\n",
        "        print(summary)\n",
        "        print(\"\\n\" + \"-\" * 60)\n",
        "        print(f\"Privacy Risk Assessment: {risk}\")\n",
        "\n",
        "\n",
        "def on_clear_clicked(b):\n",
        "    policy_input.value = \"\"\n",
        "    file_upload.value.clear()\n",
        "    upload_status.value = \"No file uploaded.\"\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "\n",
        "\n",
        "analyze_button.on_click(on_analyze_clicked)\n",
        "clear_button.on_click(on_clear_clicked)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76fcfe7d-1b54-46da-8f99-59be9aa32fb3",
      "metadata": {
        "id": "76fcfe7d-1b54-46da-8f99-59be9aa32fb3"
      },
      "source": [
        "### Step 6: Launch the Interface\n",
        "\n",
        "In this final step, all frontend components are displayed together to launch the interactive application. The user can now paste a privacy policy, generate a summary, and immediately view the corresponding privacy risk assessment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(\n",
        "    widgets.VBox([\n",
        "        policy_input,\n",
        "        widgets.HBox([file_upload, upload_status]),\n",
        "        widgets.HBox([analyze_button, clear_button]),\n",
        "        output_area\n",
        "    ])\n",
        ")\n"
      ],
      "metadata": {
        "id": "0I_dzoxzGK7V"
      },
      "id": "0I_dzoxzGK7V",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}